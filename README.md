# ğŸ™ï¸ Transkriptor â€“ Lokale Spracherkennung mit Sprecher-Diarisierung

Eine vollstÃ¤ndig lokal gehostete Web-Anwendung zur automatischen Transkription von Audio- und Videodateien mit Sprecherzuweisung.

## âœ¨ Features

- **ğŸ¯ Lokale Verarbeitung** â€“ Deine Daten verlassen nie deinen Server
- **ğŸ‘¥ Sprecher-Diarisierung** â€“ Automatische Erkennung verschiedener Sprecher
- **ğŸŒ Multi-Sprache** â€“ UnterstÃ¼tzt 20+ Sprachen (Deutsch, Englisch, etc.)
- **â±ï¸ Zeitstempel** â€“ Wortgenaue oder Segment-Zeitstempel
- **âœï¸ Editor** â€“ Transkripte direkt im Browser bearbeiten
- **ğŸ“ Export** â€“ TXT, SRT, VTT, JSON, Word-Format

## ğŸ–¥ï¸ Systemanforderungen

- **Docker** mit Docker Compose
- **NVIDIA GPU** mit mindestens 8 GB VRAM (fÃ¼r groÃŸe Modelle)
- **NVIDIA Container Toolkit** installiert
- **Hugging Face Account** (kostenlos)

### GPU Setup (falls noch nicht vorhanden)

```bash
# NVIDIA Container Toolkit installieren (Ubuntu/Debian)
curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg

curl -s -L https://nvidia.github.io/libnvidia-container/stable/deb/nvidia-container-toolkit.list | \
  sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | \
  sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list

sudo apt update && sudo apt install -y nvidia-container-toolkit
sudo nvidia-ctk runtime configure --runtime=docker
sudo systemctl restart docker
```

## ğŸš€ Installation

### 1. Repository klonen/Dateien kopieren

```bash
mkdir whisper-transcriber && cd whisper-transcriber
# Alle Dateien in dieses Verzeichnis kopieren
```

### 2. Hugging Face Token einrichten

1. Erstelle einen kostenlosen Account auf [huggingface.co](https://huggingface.co)
2. Generiere einen **READ** Token unter: https://huggingface.co/settings/tokens
3. Akzeptiere die Nutzungsbedingungen fÃ¼r diese Modelle:
   - https://huggingface.co/pyannote/segmentation-3.0
   - https://huggingface.co/pyannote/speaker-diarization-3.1

### 3. Konfiguration erstellen

```bash
# .env Datei aus Vorlage erstellen
cp .env.example .env

# Token eintragen
nano .env
# Ersetze "hf_DEIN_TOKEN_HIER" mit deinem echten Token
```

### 4. Starten

```bash
docker compose up -d
```

â³ **Erster Start dauert lÃ¤nger** â€“ Die Modelle werden heruntergeladen (~10 GB).

### 5. Ã–ffnen

Ã–ffne im Browser: **http://localhost:3000**

## ğŸ“‹ Nutzung

1. **Datei hochladen** â€“ Audio (MP3, WAV, M4A...) oder Video (MP4, MKV...)
2. **Optionen wÃ¤hlen**:
   - Sprache (automatisch oder manuell)
   - Max. Anzahl Sprecher
   - Sprecher-Erkennung ein/aus
   - Wort-Zeitstempel ein/aus
3. **Warten** â€“ Je nach DateigrÃ¶ÃŸe einige Sekunden bis Minuten
4. **Bearbeiten** â€“ Sprecher umbenennen, Text korrigieren
5. **Exportieren** â€“ Format wÃ¤hlen und herunterladen

## ğŸ›ï¸ Modelle & Performance

| Modell | VRAM | QualitÃ¤t | Geschwindigkeit |
|--------|------|----------|-----------------|
| `tiny` | ~1 GB | â­â­ | âš¡âš¡âš¡âš¡âš¡ |
| `base` | ~1 GB | â­â­â­ | âš¡âš¡âš¡âš¡ |
| `small` | ~2 GB | â­â­â­â­ | âš¡âš¡âš¡ |
| `medium` | ~5 GB | â­â­â­â­ | âš¡âš¡ |
| `large-v3` | ~10 GB | â­â­â­â­â­ | âš¡ |

Modell Ã¤ndern in `docker-compose.yml`:
```yaml
environment:
  - ASR_MODEL=medium  # oder: tiny, base, small, large-v3
```

## ğŸ”§ Konfiguration

### docker-compose.yml Optionen

```yaml
environment:
  # ASR Engine (whisperx fÃ¼r Diarization)
  - ASR_ENGINE=whisperx
  
  # ModellgrÃ¶ÃŸe
  - ASR_MODEL=large-v3
  
  # Hugging Face Token (fÃ¼r Sprecher-Erkennung)
  - HF_TOKEN=${HF_TOKEN}
```

### Ports Ã¤ndern

Frontend: Port `3000` â†’ z.B. `8080`:
```yaml
frontend:
  ports:
    - "8080:80"
```

API direkt: Port `9000`

## ğŸ› Troubleshooting

### "API offline"

```bash
# Logs prÃ¼fen
docker compose logs whisper-api

# Container neustarten
docker compose restart whisper-api
```

### GPU nicht erkannt

```bash
# NVIDIA Docker testen
docker run --rm --gpus all nvidia/cuda:12.0-base nvidia-smi

# Falls Fehler: nvidia-container-toolkit neu konfigurieren
sudo nvidia-ctk runtime configure --runtime=docker
sudo systemctl restart docker
```

### Diarization funktioniert nicht

1. HF_TOKEN in `.env` korrekt eingetragen?
2. Nutzungsbedingungen der pyannote-Modelle akzeptiert?
3. Container neu starten nach Token-Ã„nderung

### Out of Memory (GPU)

Kleineres Modell verwenden:
```yaml
- ASR_MODEL=small  # statt large-v3
```

## ğŸ“ Verzeichnisstruktur

```
whisper-transcriber/
â”œâ”€â”€ docker-compose.yml    # Container-Konfiguration
â”œâ”€â”€ .env                  # Secrets (HF_TOKEN)
â”œâ”€â”€ .env.example          # Vorlage
â””â”€â”€ frontend/
    â”œâ”€â”€ Dockerfile
    â”œâ”€â”€ nginx.conf
    â”œâ”€â”€ index.html
    â”œâ”€â”€ styles.css
    â””â”€â”€ app.js
```

## ğŸ”’ Sicherheit

- Alle Daten werden **lokal verarbeitet**
- Keine Daten werden an externe Server gesendet
- Hugging Face Token wird nur fÃ¼r Model-Downloads verwendet

## ğŸ“„ Lizenz

MIT License â€“ Frei verwendbar fÃ¼r private und kommerzielle Zwecke.

## ğŸ™ Credits

- [WhisperX](https://github.com/m-bain/whisperX) â€“ ASR mit Alignment und Diarization
- [whisper-asr-webservice](https://github.com/ahmetoner/whisper-asr-webservice) â€“ API Backend
- [pyannote-audio](https://github.com/pyannote/pyannote-audio) â€“ Speaker Diarization
